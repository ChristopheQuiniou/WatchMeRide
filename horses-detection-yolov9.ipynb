{"cells":[{"cell_type":"markdown","metadata":{},"source":["# üêé Horse Detection using Computer Vision with YOLOv9 üêé\n","\n","Welcome to our notebook on `Horse Detection using Computer Vision with YOLOv9!` In this notebook, we will walk you through the process of training a custom YOLOv9 model to detect horses in images and videos. üêé\n","\n","![image](https://wallpapers.com/images/featured/horse-h3azzzaaorg8c9ay.jpg)\n","\n","## Overview\n","\n","- **Data Collection**: We will download a dataset containing images and videos of horses from Roboflow.\n","- **Model Training**: Using YOLOv9, we will train a custom model on the dataset to accurately detect horses.\n","- **Model Evaluation**: We will evaluate the trained model's performance using validation images and videos.\n","- **Inference**: Finally, we will perform inference on new images and videos to detect horses in real-world scenarios.\n","\n","Let's dive in and explore the exciting world of horse detection with computer vision! üåü\n","\n","#### **Note:** We will display one original video with its detected one that we downloaded after running this notebook before sharing it on Kaggle"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["import glob\n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","def play_video(filename, video_title):\n","    html = ''\n","    video = open(filename,'rb').read()\n","    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n","    html += f'<div style=\"text-align:center;\">'\n","    html += f'<h3>{video_title}</h3>'\n","    html += '<video width=800 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n","    return HTML(html)"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/horses-test-videos/Horses_1.mp4'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplay_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/horses-test-videos/Horses_1.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOriginal Video\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[7], line 7\u001b[0m, in \u001b[0;36mplay_video\u001b[1;34m(filename, video_title)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay_video\u001b[39m(filename, video_title):\n\u001b[0;32m      6\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     video \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      8\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata:video/mp4;base64,\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m b64encode(video)\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[0;32m      9\u001b[0m     html \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<div style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-align:center;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/horses-test-videos/Horses_1.mp4'"]}],"source":["play_video('/kaggle/input/horses-test-videos/Horses_1.mp4', \"Original Video\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["play_video('/kaggle/input/detected-horses-videos/Detected_Horses_1.mp4', \"Detected Video\")"]},{"cell_type":"markdown","metadata":{"id":"m09A8n4djDwY"},"source":["## Before you start\n","\n","Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Settings` -> `Accelerator`, and then set it to `GPU`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5hX88yficL7","outputId":"43bfb50e-0aa8-4ce4-cf74-389545fe8357","trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"UTprsNjHja4l"},"source":["**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rowKDIT-jJ9k","outputId":"e15d746f-d9dc-4cad-d3cd-946d49783189","trusted":true},"outputs":[],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"markdown","metadata":{"id":"qWRGGT7Zjjbq"},"source":["## Clone and Install\n","\n","**NOTE:** YOLOv9 is very new. At the moment, we recommend using a fork of the main repository. The `detect.py` script contains a bug that prevents inference. This bug is patched in the fork."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pixgo4qnjdoU","trusted":true},"outputs":[],"source":["!git clone https://github.com/SkalskiP/yolov9.git\n","%cd yolov9\n","!pip install -r requirements.txt -q"]},{"cell_type":"markdown","metadata":{"id":"bcx7KoNzqpgz"},"source":["**NOTE:** Let's install the [`roboflow`](https://pypi.org/project/roboflow) package, which we will use to download our dataset from [Roboflow Universe](https://universe.roboflow.com/)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TPGqlohQqgAO","trusted":true},"outputs":[],"source":["!pip install roboflow -q"]},{"cell_type":"markdown","metadata":{"id":"X8oLIkX2l2P0"},"source":["## Download model weights\n","\n","**NOTE:** In the YOLOv9 paper, versions `yolov9-s` and `yolov9-m` are also mentioned, but the weights for these models are not yet available in the YOLOv9 [repository](https://github.com/WongKinYiu/yolov9)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7j3aUE7l1Je","trusted":true},"outputs":[],"source":["!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n","!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n","!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n","!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Au6np1JS8eRB","outputId":"ddf7bd59-9fd0-43a2-e743-9a52852930ce","trusted":true},"outputs":[],"source":["!ls -la {HOME}/weights"]},{"cell_type":"markdown","metadata":{"id":"D7fZKrxsq_td"},"source":["## Download the Dataset\n","\n","**NOTE:** The dataset must be saved inside the `{HOME}/yolov9` directory, otherwise, the training will not succeed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MyLpftfU2Q1U","trusted":true},"outputs":[],"source":["%cd {HOME}/yolov9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4J3s_2_7p_gn","trusted":true},"outputs":[],"source":["from roboflow import Roboflow\n","\n","rf = Roboflow(api_key=\"G2zfOgnsvFlAUDu2L1Vy\")\n","project = rf.workspace(\"saban-ne0tf\").project(\"horse-jehyp\")\n","version = project.version(1)\n","dataset = version.download(\"yolov9\")"]},{"cell_type":"markdown","metadata":{},"source":["### Display Some Random Training Images"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import random\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# Path to the images folder\n","images_folder = '/kaggle/working/yolov9/horse-1/train/images'\n","\n","# Function to load and display images\n","def display_images(image_paths):\n","    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n","    axes = axes.flatten()\n","    for i, image_path in enumerate(image_paths):\n","        image = Image.open(image_path)\n","        axes[i].imshow(image)\n","        axes[i].axis('off')\n","    plt.show()\n","\n","# Get a list of all image paths in the training folder\n","image_paths = [os.path.join(images_folder, filename) for filename in os.listdir(images_folder) if filename.endswith('.jpg')]\n","\n","# Shuffle the list of image paths\n","random.shuffle(image_paths)\n","\n","# Select 8 random image paths\n","random_image_paths = image_paths[:8]\n","\n","# Display the random images\n","display_images(random_image_paths)"]},{"cell_type":"markdown","metadata":{"id":"CTbGpF2IsZ24"},"source":["## Train Custom Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N68Bdf4FsMYW","trusted":true},"outputs":[],"source":["%cd {HOME}/yolov9\n","\n","!python train.py \\\n","--batch 16 --epochs 30 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n","--data {dataset.location}/data.yaml \\\n","--weights {HOME}/weights/gelan-c.pt \\\n","--cfg models/detect/gelan-c.yaml \\\n","--hyp hyp.scratch-high.yaml"]},{"cell_type":"markdown","metadata":{"id":"fpCwjSUg2Mrw"},"source":["## Examine Training Results\n","\n","**NOTE:** By default, the results of each subsequent training sessions are saved in `{HOME}/yolov9/runs/train/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WslwgMAW2Euc","outputId":"144b5202-56a6-4782-f797-763010939665","trusted":true},"outputs":[],"source":["!ls {HOME}/yolov9/runs/train/exp/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"grirpuCstpZE","outputId":"cd9b75ea-4451-4493-8a48-6ca4e848f075","trusted":true},"outputs":[],"source":["from IPython.display import Image\n","\n","Image(filename=f\"{HOME}/yolov9/runs/train/exp/results.png\", width=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qggEg7Hv1zJ6","outputId":"9fcd5ba4-da6c-45d7-a051-b0b88d7da06d","trusted":true},"outputs":[],"source":["Image(filename=f\"{HOME}/yolov9/runs/train/exp/confusion_matrix.png\", width=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xja2fjTl32Ml","outputId":"dc6b1c52-b42b-4e7b-c64d-11647e6aead9","trusted":true},"outputs":[],"source":["Image(filename=f\"{HOME}/yolov9/runs/train/exp/val_batch0_pred.jpg\", width=1000)"]},{"cell_type":"markdown","metadata":{"id":"ih1rk9O_4CYG"},"source":["## Validate Custom Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XoZv8kNE4NxS","outputId":"a13455e7-0524-46e5-c99e-4d930065b140","trusted":true},"outputs":[],"source":["%cd {HOME}/yolov9\n","\n","!python val.py \\\n","--img 640 --batch 32 --conf 0.001 --iou 0.7 --device 0 \\\n","--data {dataset.location}/data.yaml \\\n","--weights {HOME}/yolov9/runs/train/exp/weights/best.pt"]},{"cell_type":"markdown","metadata":{"id":"qJJ5fiqT6mEq"},"source":["## Inference with Custom Model on some images and videos"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Detect some test images\n","!python detect.py \\\n","--img 1280 --conf 0.1 --device 0 \\\n","--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n","--source /kaggle/input/horse-test-images"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import glob\n","\n","# Display some test images\n","for image_path in glob.glob(f'{HOME}/yolov9/runs/detect/exp/*.jpg'):\n","      display(Image(filename=image_path, width=600))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Detect some test videos\n","!python detect.py \\\n","--img 1280 --conf 0.1 --device 0 \\\n","--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n","--source /kaggle/input/horses-test-videos"]},{"cell_type":"markdown","metadata":{},"source":["#### You can download the detected videos from output environment and the following is an example one of the detected videos like we displayed at the start of the notebook"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["play_video('/kaggle/input/detected-horses-videos/Detected_Horses_9.mp4', \"Detected Video\")"]},{"cell_type":"markdown","metadata":{},"source":["# How to Train YOLOv9 on a Custom Dataset\n","---\n","\n","[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/train-yolov9-model/)\n","[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/WongKinYiu/yolov9)\n","[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/XHT2c8jT3Bc)\n","[![arXiv](https://img.shields.io/badge/arXiv-2402.13616-b31b1b.svg)](https://arxiv.org/pdf/2402.13616.pdf)"]},{"cell_type":"markdown","metadata":{},"source":["# Made by: Abdelrahman Eldaba üë®‚Äçüíª\n","\n","Check out my website with a portfolio [Here](https://sites.google.com/view/abdelrahman-eldaba110) üåü\n","\n","Connect with me on [LinkedIn](https://www.linkedin.com/in/abdelrahmaneldaba/) üåê\n","\n","Look at my [GitHub](https://github.com/Abdelrahman47-code) üöÄ"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4795163,"sourceId":8116231,"sourceType":"datasetVersion"},{"datasetId":4799884,"sourceId":8122796,"sourceType":"datasetVersion"},{"datasetId":4804440,"sourceId":8128845,"sourceType":"datasetVersion"}],"dockerImageVersionId":30684,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
