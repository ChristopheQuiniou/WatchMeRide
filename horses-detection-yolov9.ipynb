{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8116231,"sourceType":"datasetVersion","datasetId":4795163},{"sourceId":8122796,"sourceType":"datasetVersion","datasetId":4799884},{"sourceId":8128845,"sourceType":"datasetVersion","datasetId":4804440}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üêé Horse Detection using Computer Vision with YOLOv9 üêé\n\nWelcome to our notebook on `Horse Detection using Computer Vision with YOLOv9!` In this notebook, we will walk you through the process of training a custom YOLOv9 model to detect horses in images and videos. üêé\n\n![image](https://wallpapers.com/images/featured/horse-h3azzzaaorg8c9ay.jpg)\n\n## Overview\n\n- **Data Collection**: We will download a dataset containing images and videos of horses from Roboflow.\n- **Model Training**: Using YOLOv9, we will train a custom model on the dataset to accurately detect horses.\n- **Model Evaluation**: We will evaluate the trained model's performance using validation images and videos.\n- **Inference**: Finally, we will perform inference on new images and videos to detect horses in real-world scenarios.\n\nLet's dive in and explore the exciting world of horse detection with computer vision! üåü\n\n#### **Note:** We will display one original video with its detected one that we downloaded after running this notebook before sharing it on Kaggle","metadata":{}},{"cell_type":"code","source":"import glob\nfrom IPython.display import HTML\nfrom base64 import b64encode\n\ndef play_video(filename, video_title):\n    html = ''\n    video = open(filename,'rb').read()\n    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n    html += f'<div style=\"text-align:center;\">'\n    html += f'<h3>{video_title}</h3>'\n    html += '<video width=800 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n    return HTML(html)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"play_video('/kaggle/input/horses-test-videos/Horses_1.mp4', \"Original Video\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"play_video('/kaggle/input/detected-horses-videos/Detected_Horses_1.mp4', \"Detected Video\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Before you start\n\nLet's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Settings` -> `Accelerator`, and then set it to `GPU`.","metadata":{"id":"m09A8n4djDwY"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"_5hX88yficL7","outputId":"43bfb50e-0aa8-4ce4-cf74-389545fe8357","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant.","metadata":{"id":"UTprsNjHja4l"}},{"cell_type":"code","source":"import os\nHOME = os.getcwd()\nprint(HOME)","metadata":{"id":"rowKDIT-jJ9k","outputId":"e15d746f-d9dc-4cad-d3cd-946d49783189","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clone and Install\n\n**NOTE:** YOLOv9 is very new. At the moment, we recommend using a fork of the main repository. The `detect.py` script contains a bug that prevents inference. This bug is patched in the fork.","metadata":{"id":"qWRGGT7Zjjbq"}},{"cell_type":"code","source":"!git clone https://github.com/SkalskiP/yolov9.git\n%cd yolov9\n!pip install -r requirements.txt -q","metadata":{"id":"pixgo4qnjdoU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NOTE:** Let's install the [`roboflow`](https://pypi.org/project/roboflow) package, which we will use to download our dataset from [Roboflow Universe](https://universe.roboflow.com/).","metadata":{"id":"bcx7KoNzqpgz"}},{"cell_type":"code","source":"!pip install roboflow -q","metadata":{"id":"TPGqlohQqgAO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download model weights\n\n**NOTE:** In the YOLOv9 paper, versions `yolov9-s` and `yolov9-m` are also mentioned, but the weights for these models are not yet available in the YOLOv9 [repository](https://github.com/WongKinYiu/yolov9).","metadata":{"id":"X8oLIkX2l2P0"}},{"cell_type":"code","source":"!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt","metadata":{"id":"h7j3aUE7l1Je","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -la {HOME}/weights","metadata":{"id":"Au6np1JS8eRB","outputId":"ddf7bd59-9fd0-43a2-e743-9a52852930ce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download the Dataset\n\n**NOTE:** The dataset must be saved inside the `{HOME}/yolov9` directory, otherwise, the training will not succeed.","metadata":{"id":"D7fZKrxsq_td"}},{"cell_type":"code","source":"%cd {HOME}/yolov9","metadata":{"id":"MyLpftfU2Q1U","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from roboflow import Roboflow\n\nrf = Roboflow(api_key=\"G2zfOgnsvFlAUDu2L1Vy\")\nproject = rf.workspace(\"saban-ne0tf\").project(\"horse-jehyp\")\nversion = project.version(1)\ndataset = version.download(\"yolov9\")","metadata":{"id":"4J3s_2_7p_gn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Display Some Random Training Images","metadata":{}},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Path to the images folder\nimages_folder = '/kaggle/working/yolov9/horse-1/train/images'\n\n# Function to load and display images\ndef display_images(image_paths):\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    axes = axes.flatten()\n    for i, image_path in enumerate(image_paths):\n        image = Image.open(image_path)\n        axes[i].imshow(image)\n        axes[i].axis('off')\n    plt.show()\n\n# Get a list of all image paths in the training folder\nimage_paths = [os.path.join(images_folder, filename) for filename in os.listdir(images_folder) if filename.endswith('.jpg')]\n\n# Shuffle the list of image paths\nrandom.shuffle(image_paths)\n\n# Select 8 random image paths\nrandom_image_paths = image_paths[:8]\n\n# Display the random images\ndisplay_images(random_image_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Custom Model","metadata":{"id":"CTbGpF2IsZ24"}},{"cell_type":"code","source":"%cd {HOME}/yolov9\n\n!python train.py \\\n--batch 16 --epochs 30 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n--data {dataset.location}/data.yaml \\\n--weights {HOME}/weights/gelan-c.pt \\\n--cfg models/detect/gelan-c.yaml \\\n--hyp hyp.scratch-high.yaml","metadata":{"id":"N68Bdf4FsMYW","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Examine Training Results\n\n**NOTE:** By default, the results of each subsequent training sessions are saved in `{HOME}/yolov9/runs/train/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter.","metadata":{"id":"fpCwjSUg2Mrw"}},{"cell_type":"code","source":"!ls {HOME}/yolov9/runs/train/exp/","metadata":{"id":"WslwgMAW2Euc","outputId":"144b5202-56a6-4782-f797-763010939665","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\n\nImage(filename=f\"{HOME}/yolov9/runs/train/exp/results.png\", width=1000)","metadata":{"id":"grirpuCstpZE","outputId":"cd9b75ea-4451-4493-8a48-6ca4e848f075","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename=f\"{HOME}/yolov9/runs/train/exp/confusion_matrix.png\", width=1000)","metadata":{"id":"qggEg7Hv1zJ6","outputId":"9fcd5ba4-da6c-45d7-a051-b0b88d7da06d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename=f\"{HOME}/yolov9/runs/train/exp/val_batch0_pred.jpg\", width=1000)","metadata":{"id":"Xja2fjTl32Ml","outputId":"dc6b1c52-b42b-4e7b-c64d-11647e6aead9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validate Custom Model","metadata":{"id":"ih1rk9O_4CYG"}},{"cell_type":"code","source":"%cd {HOME}/yolov9\n\n!python val.py \\\n--img 640 --batch 32 --conf 0.001 --iou 0.7 --device 0 \\\n--data {dataset.location}/data.yaml \\\n--weights {HOME}/yolov9/runs/train/exp/weights/best.pt","metadata":{"id":"XoZv8kNE4NxS","outputId":"a13455e7-0524-46e5-c99e-4d930065b140","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference with Custom Model on some images and videos","metadata":{"id":"qJJ5fiqT6mEq"}},{"cell_type":"code","source":"# Detect some test images\n!python detect.py \\\n--img 1280 --conf 0.1 --device 0 \\\n--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n--source /kaggle/input/horse-test-images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\n\n# Display some test images\nfor image_path in glob.glob(f'{HOME}/yolov9/runs/detect/exp/*.jpg'):\n      display(Image(filename=image_path, width=600))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect some test videos\n!python detect.py \\\n--img 1280 --conf 0.1 --device 0 \\\n--weights {HOME}/yolov9/runs/train/exp/weights/best.pt \\\n--source /kaggle/input/horses-test-videos","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### You can download the detected videos from output environment and the following is an example one of the detected videos like we displayed at the start of the notebook","metadata":{}},{"cell_type":"code","source":"play_video('/kaggle/input/detected-horses-videos/Detected_Horses_9.mp4', \"Detected Video\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How to Train YOLOv9 on a Custom Dataset\n---\n\n[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/train-yolov9-model/)\n[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/WongKinYiu/yolov9)\n[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/XHT2c8jT3Bc)\n[![arXiv](https://img.shields.io/badge/arXiv-2402.13616-b31b1b.svg)](https://arxiv.org/pdf/2402.13616.pdf)","metadata":{}},{"cell_type":"markdown","source":"# Made by: Abdelrahman Eldaba üë®‚Äçüíª\n\nCheck out my website with a portfolio [Here](https://sites.google.com/view/abdelrahman-eldaba110) üåü\n\nConnect with me on [LinkedIn](https://www.linkedin.com/in/abdelrahmaneldaba/) üåê\n\nLook at my [GitHub](https://github.com/Abdelrahman47-code) üöÄ","metadata":{}}]}